import os
import re
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph
from pydantic import BaseModel, Field

# Load environment variables from .env file
load_dotenv()

# Graph State Model
class State(BaseModel):
    """
    Represents the state of the mathematical question processing flow.
    
    Attributes:
        question (str): Question submitted by the user.
        question_json (dict | None): JSON structure containing question details (if valid).
        error (str | None): Error message in case of invalid input.
        answer (str | None): Answer generated by the AI model.
    """
    question: str
    question_json: dict | None = None
    error: str | None = None
    answer: str | None = None

# Model to structure mathematical questions
class MathQuestion(BaseModel):
    """
    Represents a structured mathematical question.
    
    Attributes:
        question (str): Text of the question submitted by the user.
        category (str): Question category (default "mathematics").
    """
    question: str = Field(description="Mathematical question submitted by the user")
    category: str = Field(default="mathematics", description="Category of the question")

# Input validator
def validate_question(question: str) -> bool:
    """
    Checks whether the submitted question contains valid mathematical elements.
    
    Parameters:
        question (str): Text of the user's question.
    
    Returns:
        bool: True if the question is mathematical, False otherwise.
    """
    math_pattern = re.compile(r'[\d+\-*/=]')  # Looks for numbers and mathematical operators
    math_words = [
        "sum", "subtraction", "multiplication", "division", "equation", "calculate", "solve"
    ]
    
    return bool(math_pattern.search(question) or any(word in question.lower() for word in math_words))

# Receiver Node
def receiver(state: State) -> State:
    """
    Processes the received question and validates whether it is mathematical.
    
    Parameters:
        state (State): Current state containing the user's question.
    
    Returns:
        State: New state with structured question or error message.
    """
    if validate_question(state.question):
        return State(question=state.question, question_json=MathQuestion(question=state.question).model_dump())
    else:
        return State(question=state.question, error="Invalid question. Please submit a mathematical problem.")

# AI Model Configuration
llm = ChatOpenAI(
    model="gpt-3.5-turbo", 
    temperature=0,  # Ensures more deterministic responses
    api_key=os.getenv("OPENAI_API_KEY")
)

# Virtual Teacher Node
def virtual_teacher(state: State) -> State:
    """
    Receives a valid mathematical question and returns an AI-generated answer.
    
    Parameters:
        state (State): State containing the structured question.
    
    Returns:
        State: New state containing the generated answer or the original state in case of error.
    """
    if state.question_json:
        answer = llm.invoke(f"Solve the following mathematical problem: {state.question_json['question']}")
        return State(question=state.question, question_json=state.question_json, answer=answer.content)
    return state  # Maintains state in case of error

# Creating the state graph to manage the flow

graph = StateGraph(State)  # Defines the state model

graph.add_node("receiver", receiver)  # Adds the receiver node

graph.add_node("virtual_teacher", virtual_teacher)  # Adds the virtual teacher node

# Connecting the nodes

graph.add_edge("receiver", "virtual_teacher")  # The receiver leads to the virtual teacher

# Setting the initial node

graph.set_entry_point("receiver")

# Compiling the flow
executor = graph.compile()

# Testing the flow with a sample question
question = "Solve the equation 2x + 3 = 7"
result = executor.invoke(State(question=question))

# Getting the answer
result_answer = result['answer']

# Improving answer formatting
formatted_response = result_answer.replace("\n", "\n")

# Displaying the answer in the terminal
print(formatted_response)
